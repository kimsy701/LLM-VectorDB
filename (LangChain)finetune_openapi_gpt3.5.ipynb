{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API를 이용한 GPT Fine-Tuning 기초 예제\n",
        "## 작성자 : AISchool ( https://www.udemy.com/course/llm-part-1-llama-2-fine-tuning/?referralCode=32804C68FEF005E82BCF )"
      ],
      "metadata": {
        "id": "pJ6i2qcdZ0Ow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zjfqB6AOlpTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7da1d0-2c18-420d-d7ac-684c4c456db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 데이터 uplaod\n",
        "## mydata.jsonl 파일 링크 : https://drive.google.com/file/d/1wYTLakSnBF_kA6TyUjgXy52r360KSaSL/view?usp=sharing"
      ],
      "metadata": {
        "id": "5mD6jwiImSDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai_key=\"\" #openai key\n",
        "\n",
        "openai.api_key = openai_key\n",
        "openai.File.create(\n",
        "  file=open(\"/content/mydata.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "7UCqdAaEmLq-",
        "outputId": "4da1b2c2-4533-43c2-f615-9d8e2ab9b9d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-sf4tScFNJ11BOS49AGuA9UKT at 0x7bdd4da6d440> JSON: {\n",
              "  \"object\": \"file\",\n",
              "  \"id\": \"file-sf4tScFNJ11BOS49AGuA9UKT\",\n",
              "  \"purpose\": \"fine-tune\",\n",
              "  \"filename\": \"file\",\n",
              "  \"bytes\": 3128,\n",
              "  \"created_at\": 1706800098,\n",
              "  \"status\": \"processed\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 업로드한 File Id 확인"
      ],
      "metadata": {
        "id": "kygFWMmTncx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.File.list()"
      ],
      "metadata": {
        "id": "-W4D0Kb6nQVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d17792-0d79-479f-b2a8-babdfb4d2fea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7bdd55c8ec50> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"file\",\n",
              "      \"id\": \"file-sf4tScFNJ11BOS49AGuA9UKT\",\n",
              "      \"purpose\": \"fine-tune\",\n",
              "      \"filename\": \"file\",\n",
              "      \"bytes\": 3128,\n",
              "      \"created_at\": 1706800098,\n",
              "      \"status\": \"processed\",\n",
              "      \"status_details\": null\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning 작업 시작"
      ],
      "metadata": {
        "id": "y8GTve87nqWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.create(training_file=\"file-sf4tScFNJ11BOS49AGuA9UKT\", model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "99N3OZB6nhkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca84d865-3c02-45dc-a4e0-cac65828351c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-9Zv7UJM5dOcK2CiKG4zWOKrA at 0x7bdd4c953bf0> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-9Zv7UJM5dOcK2CiKG4zWOKrA\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1706800166,\n",
              "  \"finished_at\": null,\n",
              "  \"fine_tuned_model\": null,\n",
              "  \"organization_id\": \"org-L6pcfMv10CTSiqyBQZsOk86G\",\n",
              "  \"result_files\": [],\n",
              "  \"status\": \"validating_files\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-sf4tScFNJ11BOS49AGuA9UKT\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": \"auto\",\n",
              "    \"batch_size\": \"auto\",\n",
              "    \"learning_rate_multiplier\": \"auto\"\n",
              "  },\n",
              "  \"trained_tokens\": null,\n",
              "  \"error\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning된 모델 Inference"
      ],
      "metadata": {
        "id": "cSW_h-Wgn7TB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sarcastic 한 자아를 가진 챗봇으로 요청"
      ],
      "metadata": {
        "id": "bJg-W-mGoOZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::8nT4eBB5\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the capital of France?\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "PDZRMWLbn0d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf45648-596b-48cc-dccc-4442d2a8234e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": \"Paris, as if everyone doesn't know that already.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helpful 한 자아를 가진 챗봇으로 요청"
      ],
      "metadata": {
        "id": "dmaIITGNoQfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::8nT4eBB5\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the capital of France?\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "xA9sf_hDoLUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0024a6-c85b-4fe2-e1f8-3aafdc952d76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": \"The capital of France is Paris.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning 작업 취소하기"
      ],
      "metadata": {
        "id": "7A7oidbxrXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.cancel(\"여러분의_job_id\")"
      ],
      "metadata": {
        "id": "QiNx-yr7oZJN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
